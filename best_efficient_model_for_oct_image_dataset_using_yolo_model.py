# -*- coding: utf-8 -*-
"""Best_efficient_model_for_OCT_Image_dataset_using_YOLO_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F4b-B7q9xmTepPNKE9s2Wl3yqJgdk5iV
"""

!mkdir OCT

cd OCT

from google.colab import drive
drive.mount('/content/drive')

!cd /content/drive/MyDrive/THISIS_PROJECT_OCT

from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns

def eval_model(model, test_data, test_labels):
    print("Evaluating model")

    # Predictions
    predictions = model.predict(test_data)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(test_labels, axis=1)

    # Loss and accuracy
    loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)
    print(f"avg loss (test): {loss:.4f}")
    print(f"avg acc (test): {accuracy:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(true_classes, predicted_classes)
    print("Confusion Matrix:\n", cm)

    # Metrics
    precision, recall, f1_score, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='macro')
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1_score:.4f}")

    # ROC-AUC
    roc_auc = roc_auc_score(test_labels, predictions, multi_class="ovr")
    print(f"ROC-AUC: {roc_auc:.4f}")

    # Confusion Matrix Plot
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'], yticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'])
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    # ROC Curves
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(num_classes):
        fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])
        roc_auc[i] = roc_auc_score(test_labels[:, i], predictions[:, i])

    plt.figure()
    for i in range(num_classes):
        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves')
    plt.legend(loc='lower right')
    plt.show()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def load_data(data_dir, img_size=(224, 224), batch_size=32):
    """
    Loads OCT data from the directory and prepares train, validation, and test sets.
    """

    train_datagen = ImageDataGenerator(rescale=1./255,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True)
    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        f"{data_dir}/train",
        target_size=img_size,
        batch_size=batch_size,
        class_mode='categorical'
    )


    test_generator = test_datagen.flow_from_directory(
        f"{data_dir}/test",
        target_size=img_size,
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False
    )

    return train_generator, test_generator

from tensorflow.keras.applications import VGG19, Xception
from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate
from tensorflow.keras.models import Model

def create_vgg19_extractor(input_shape):
    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in base_model.layers:
        layer.trainable = False
    x = GlobalAveragePooling2D()(base_model.output)
    return Model(inputs=base_model.input, outputs=x)

def create_xception_extractor(input_shape):
    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in base_model.layers:
        layer.trainable = False
    x = GlobalAveragePooling2D()(base_model.output)
    return Model(inputs=base_model.input, outputs=x)

def create_yolo_based_model(input_shape, num_classes):
    input_layer = Input(shape=input_shape)

    # Extract features from VGG19 and Xception
    vgg_features = create_vgg19_extractor(input_shape)(input_layer)
    xception_features = create_xception_extractor(input_shape)(input_layer)

    # Concatenate features
    combined_features = Concatenate()([vgg_features, xception_features])

    # YOLO Head for bounding box and disease classification
    x = Dense(256, activation='relu')(combined_features)
    yolo_output = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=input_layer, outputs=yolo_output)
    return model

import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint

def train_model(data_dir, input_shape=(224, 224, 3), num_classes=4, epochs=20, batch_size=32):
    # Load only the training and test data (no validation data)
    # The load_data function returns only two values: train_generator and test_generator
    train_generator, test_generator = load_data(data_dir, img_size=input_shape[:2], batch_size=batch_size)

    # Create the model
    model = create_yolo_based_model(input_shape, num_classes)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Define checkpoints to save the best model based on training accuracy
    # Changed the filepath to end with .keras
    checkpoint = ModelCheckpoint("models/best_model.keras", monitor='accuracy', save_best_only=True, mode='max')

    # Train the model without validation data
    model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // batch_size,
        epochs=epochs,
        callbacks=[checkpoint]
    )

    # Evaluate on the test set after training
    test_loss, test_accuracy = model.evaluate(test_generator)
    print(f"Test Loss: {test_loss}")
    print(f"Test Accuracy: {test_accuracy}")

    # Save final model
    # Changed the filepath to end with .keras
    model.save("models/final_model.keras")

if __name__ == "__main__":
    data_dir = "/content/drive/MyDrive/THISIS_PROJECT_OCT/data"
    train_model(data_dir)

import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns

def eval_model(model, test_data, test_labels):
    print("Evaluating model")

    # Predictions
    predictions = model.predict(test_data)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(test_labels, axis=1)

    # Loss and accuracy
    loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)
    print(f"avg loss (test): {loss:.4f}")
    print(f"avg acc (test): {accuracy:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(true_classes, predicted_classes)
    print("Confusion Matrix:\n", cm)

    # Metrics
    precision, recall, f1_score, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='macro')
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1_score:.4f}")

    # ROC-AUC
    if len(np.unique(true_classes)) > 1:
        roc_auc = roc_auc_score(test_labels, predictions, multi_class="ovr")
        print(f"ROC-AUC: {roc_auc:.4f}")
    else:
        print("ROC-AUC is not defined for a single class present in y_true.")

    # Confusion Matrix Plot
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'], yticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'])
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    # ROC Curves
    num_classes = test_labels.shape[1]
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    plt.figure()
    for i in range(num_classes):
        if len(np.unique(test_labels[:, i])) > 1:
            fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])
            roc_auc[i] = roc_auc_score(test_labels[:, i], predictions[:, i])
            plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves')
    plt.legend(loc='lower right')
    plt.show()

def load_data(data_dir):
    # Assuming data loading is handled by a function that returns train and test generators
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)
    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)

    train_generator = train_datagen.flow_from_directory(
        directory=f"{data_dir}/train",
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical'
    )

    test_generator = test_datagen.flow_from_directory(
        directory=f"{data_dir}/test",
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )

    return train_generator, test_generator

def train_model(data_dir):
    # Load training data
    train_generator, _ = load_data(data_dir)

    # Simple CNN Model for demonstration
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(4, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    model.fit(train_generator, epochs=10)
    model.save("models/best_model.keras")
    print("Model trained and saved.")

if __name__ == "__main__":
    data_dir = "/content/drive/MyDrive/THISIS_PROJECT_OCT/data"

    # Train the model
    train_model(data_dir)

    # Load the trained model
    model_path = "models/best_model.keras"
    model = tf.keras.models.load_model(model_path)

    # Load test data using load_data function
    _, test_generator = load_data(data_dir)

    # Get the entire test dataset
    x_test, y_test = [], []
    for batch_x, batch_y in test_generator:
        x_test.extend(batch_x)
        y_test.extend(batch_y)
        if len(x_test) >= test_generator.samples:
            break

    test_data, test_labels = np.array(x_test), np.array(y_test)

    # Evaluate the model
    eval_model(model, test_data, test_labels)

from tensorflow.keras.applications import InceptionV3, NASNetLarge
from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Concatenate
from tensorflow.keras.models import Model

def create_inception_extractor(input_shape):
    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in base_model.layers:
        layer.trainable = False
    x = GlobalAveragePooling2D()(base_model.output)
    return Model(inputs=base_model.input, outputs=x)

def create_nasnet_extractor(input_shape):
    base_model = NASNetLarge(weights='imagenet', include_top=False, input_shape=input_shape)
    for layer in base_model.layers:
        layer.trainable = False
    x = GlobalAveragePooling2D()(base_model.output)
    return Model(inputs=base_model.input, outputs=x)

def create_yolo_based_model(input_shape, num_classes):
    input_layer = Input(shape=input_shape)

    # Extract features from InceptionV3 and NASNetLarge
    inception_features = create_inception_extractor(input_shape)(input_layer)
    nasnet_features = create_nasnet_extractor(input_shape)(input_layer)

    # Concatenate features
    combined_features = Concatenate()([inception_features, nasnet_features])

    # YOLO Head for bounding box and disease classification
    x = Dense(256, activation='relu')(combined_features)
    yolo_output = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=input_layer, outputs=yolo_output)
    return model

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def load_data(data_dir, img_size=(224, 224), batch_size=32):
    """
    Loads OCT data from the directory and prepares train, validation, and test sets.
    """

    train_datagen = ImageDataGenerator(rescale=1./255,
                                       shear_range=0.2,
                                       zoom_range=0.2,
                                       horizontal_flip=True)
    test_datagen = ImageDataGenerator(rescale=1./255)

    train_generator = train_datagen.flow_from_directory(
        f"{data_dir}/train",
        target_size=img_size,
        batch_size=batch_size,
        class_mode='categorical'
    )


    test_generator = test_datagen.flow_from_directory(
        f"{data_dir}/test",
        target_size=img_size,
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False
    )

    return train_generator, test_generator

import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns
import os
def eval_model(model, test_data, test_labels):
    print("Evaluating model")

    # Predictions
    predictions = model.predict(test_data)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = np.argmax(test_labels, axis=1)

    # Loss and accuracy
    loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)
    print(f"avg loss (test): {loss:.4f}")
    print(f"avg acc (test): {accuracy:.4f}")

    # Confusion Matrix
    cm = confusion_matrix(true_classes, predicted_classes)
    print("Confusion Matrix:\n", cm)

    # Metrics
    precision, recall, f1_score, _ = precision_recall_fscore_support(true_classes, predicted_classes, average='macro')
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1_score:.4f}")

    # ROC-AUC
    if len(np.unique(true_classes)) > 1:
        roc_auc = roc_auc_score(test_labels, predictions, multi_class="ovr")
        print(f"ROC-AUC: {roc_auc:.4f}")
    else:
        print("ROC-AUC is not defined for a single class present in y_true.")

    # Confusion Matrix Plot
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'], yticklabels=['CNV', 'DME', 'DRUSEN', 'NORMAL'])
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

    # ROC Curves
    num_classes = test_labels.shape[1]
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    plt.figure()
    for i in range(num_classes):
        if len(np.unique(test_labels[:, i])) > 1:
            fpr[i], tpr[i], _ = roc_curve(test_labels[:, i], predictions[:, i])
            roc_auc[i] = roc_auc_score(test_labels[:, i], predictions[:, i])
            plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curves')
    plt.legend(loc='lower right')
    plt.show()

def load_data(data_dir):
    # Assuming data loading is handled by a function that returns train and test generators
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)
    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)

    train_generator = train_datagen.flow_from_directory(
        directory=f"{data_dir}/train",
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical'
    )

    test_generator = test_datagen.flow_from_directory(
        directory=f"{data_dir}/test",
        target_size=(224, 224),
        batch_size=32,
        class_mode='categorical',
        shuffle=False
    )

    return train_generator, test_generator

def train_model(data_dir):
    # Load training data
    train_generator, _ = load_data(data_dir)

    # Simple CNN Model for demonstration
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D((2, 2)),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(4, activation='softmax')
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    os.makedirs("models", exist_ok=True)

    model.fit(train_generator, epochs=10)
    model.save("models/best_model.keras")
    print("Model trained and saved.")

if __name__ == "__main__":
    data_dir = "/content/drive/MyDrive/THISIS_PROJECT_OCT/data"

    # Train the model
    train_model(data_dir)

    # Load the trained model
    model_path = "models/best_model.keras"
    model = tf.keras.models.load_model(model_path)

    # Load test data using load_data function
    _, test_generator = load_data(data_dir)

    # Get the entire test dataset
    x_test, y_test = [], []
    for batch_x, batch_y in test_generator:
        x_test.extend(batch_x)
        y_test.extend(batch_y)
        if len(x_test) >= test_generator.samples:
            break

    test_data, test_labels = np.array(x_test), np.array(y_test)

    # Evaluate the model
    eval_model(model, test_data, test_labels)

!pip install yolov5

# Commented out IPython magic to ensure Python compatibility.
!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!git clone https://github.com/ultralytics/yolov5  # clone repo
# %cd yolov5
!pip install -r requirements.txt  # install dependencies

import os
import glob
import torch
import torch.nn as nn
from torchvision import models, transforms
from yolov5.models.yolo import Model
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import psutil
from PIL import Image
from sklearn.preprocessing import LabelEncoder

# Set paths and configurations
data_path = r"/content/drive/MyDrive/THISIS_PROJECT_OCT/data"
model_save_path = "./models1"
os.makedirs(model_save_path, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
cpu_count = psutil.cpu_count(logical=True)

# Custom Dataset Class
class CustomDataset(Dataset):
    def __init__(self, data_path, mode='train', img_size=(224, 224)):
        self.image_paths = glob.glob(os.path.join(data_path, mode, '*', '*.jpeg'))
        if not self.image_paths:
            raise ValueError(f"No image files found in {os.path.join(data_path, mode)}")
        self.img_size = img_size

        # Extract labels from image paths
        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.image_paths]
        self.label_encoder = LabelEncoder()
        self.labels = self.label_encoder.fit_transform(self.labels)

        # Create a mapping from class index to bounding boxes
        self.bboxes = self.create_bounding_boxes()  # Placeholder for bounding box creation

    def create_bounding_boxes(self):
        # Implement logic to create bounding boxes for each image
        # Format: [x_center, y_center, width, height, class_id]
        # Here, we provide dummy bounding boxes; you need to replace this logic with actual bounding box data
        return [[0.5, 0.5, 1.0, 1.0, self.labels[i]] for i in range(len(self.image_paths))]  # Dummy example

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')

        # Resize the image
        transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.ToTensor(),
        ])
        image = transform(image)

        # Create target tensor
        target = self.bboxes[idx]  # Get the bounding box for the current image
        target_tensor = torch.tensor(target, dtype=torch.float32)  # Convert to tensor

        return image, target_tensor

# Backbones to evaluate
backbones = {
    "ResNet50V2": models.resnet50(pretrained=True),
    "EfficientNetB7": models.efficientnet_b7(pretrained=True),
    "InceptionV3": models.inception_v3(pretrained=True),
    "DenseNet201": models.densenet201(pretrained=True),
}

# Custom YOLO loss function
def custom_yolo_loss(predictions, targets):
    """
    Custom YOLO loss function.

    Parameters:
    - predictions: model predictions (logits) from the YOLO model
    - targets: ground truth labels (bounding boxes + class labels)

    Returns:
    - total_loss: computed loss
    """
    # Unpack predictions
    batch_size = predictions.size(0)

    # Assuming predictions are of shape [batch_size, num_anchors, grid_size, grid_size, 4+num_classes]
    pred_conf = predictions[..., 4:5]  # Objectness score
    pred_cls = predictions[..., 5:]      # Class scores
    pred_boxes = predictions[..., :4]    # Bounding box coordinates

    # Compute loss components
    class_loss = nn.BCEWithLogitsLoss()(pred_cls, targets[..., 5:])  # Adjust targets for class scores
    box_loss = nn.MSELoss()(pred_boxes, targets[..., :4])            # Assuming targets are in the correct format
    conf_loss = nn.BCEWithLogitsLoss()(pred_conf, targets[..., 4:5]) # Objectness score loss

    # Total loss
    total_loss = class_loss + box_loss + conf_loss

    return total_loss

# Training function with mixed-precision and CPU-GPU load balancing
def train_with_backbone(backbone_name, backbone_model):
    print(f"\nStarting training with backbone: {backbone_name}")

    # Initialize YOLO model with custom backbone
    yolo_model = Model(cfg=r"/content/yolov5/models/yolov5s.yaml", ch=3, nc=4)
    yolo_model.backbone = backbone_model  # Set the custom backbone

    # Move model to device (GPU) and to half precision
    yolo_model.to(device).half()

    # Create dataset and dataloader
    dataset = CustomDataset(data_path, mode='train')
    train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=cpu_count)

    # Set the optimizer after moving the model
    optimizer = torch.optim.Adam(yolo_model.parameters(), lr=0.001)

    # Mixed precision training setup
    scaler = torch.amp.GradScaler()

    # Define training configuration
    train_cfg = {
        "epochs": 10,
        "weights": yolo_model,
        "name": f"{backbone_name}_OCT",
        "device": device,
        "dataloader": train_loader,
    }

    # Training loop
    for epoch in range(train_cfg["epochs"]):
        running_loss = 0.0

        print(f"\nEpoch {epoch + 1}/{train_cfg['epochs']}")
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{train_cfg['epochs']}", leave=False)

        for images, labels in progress_bar:
            images = images.to(device).half()  # Move images to device and half precision
            labels = labels.to(device)  # Move labels to the same device as images

            # Zero gradients
            yolo_model.zero_grad()

            # Forward pass with mixed precision
            with torch.amp.autocast(device_type='cuda'):
                outputs = yolo_model(images)

            # YOLO output processing
            if isinstance(outputs, list):
                predictions = outputs[0]  # Assuming outputs[0] contains the necessary predictions
            else:
                predictions = outputs.logits  # Use logits from outputs if available

            # Compute loss
            loss = custom_yolo_loss(predictions, labels)  # Compute the loss

            # Backward pass and optimization
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()

            # Update progress bar with current loss
            progress_bar.set_postfix(loss=loss.item())

        print(f"End of Epoch [{epoch + 1}], Loss: {running_loss / len(train_loader):.4f}")

    # Save model checkpoint
    torch.save(yolo_model.state_dict(), os.path.join(model_save_path, f"{backbone_name}_OCT.pth"))
    print(f"Model saved for backbone: {backbone_name}\n")

# Evaluate model accuracy and mAP
def evaluate_model(weights_path):
    print(f"\nEvaluating model at {weights_path}")
    # Adjust the evaluation logic as per your requirement
    # Note: You will need to implement or adapt the evaluation logic to compute mAP based on your setup.
    # This is a placeholder.
    results = {"mAP": 0.0, "precision": 0.0}  # Replace this with actual evaluation logic
    print(f"Evaluation Results - mAP: {results['mAP']:.4f}, Accuracy: {results['precision']:.4f}")

# Run training and evaluation for each backbone
if __name__ == "__main__":
    for backbone_name, backbone_model in backbones.items():
        # Train with custom backbone
        train_with_backbone(backbone_name, backbone_model)

        # Evaluate model performance
        model_path = os.path.join(model_save_path, f"{backbone_name}_OCT.pth")
        evaluate_model(model_path)

    print("Training and evaluation completed for all backbones.")

# Training function with mixed-precision and CPU-GPU load balancing
def train_with_backbone(backbone_name, backbone_model):
    print(f"\nStarting training with backbone: {backbone_name}")

    # Initialize YOLO model with custom backbone
    yolo_model = Model(cfg=r"/content/yolov5/yolov5/models/yolov5s.yaml", ch=3, nc=4)
    yolo_model.backbone = backbone_model  # Set the custom backbone

    # Create dataset and dataloader
    dataset = CustomDataset(data_path, mode='train')  # Load training dataset
    train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=cpu_count)

    # Mixed precision training setup
    scaler = torch.amp.GradScaler()

    # Define training configuration
    train_cfg = {
        "epochs": 10,  # Shorten for testing; adjust based on data and goals
        "weights": yolo_model,
        "name": f"{backbone_name}_OCT",
        "device": device,
        "dataloader": train_loader,  # Add dataloader here if necessary
    }

    # Training loop
    for epoch in range(train_cfg["epochs"]):
        running_loss = 0.0
        correct = 0
        total = 0

        print(f"\nEpoch {epoch + 1}/{train_cfg['epochs']}")
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{train_cfg['epochs']}", leave=False)

        for images in progress_bar:
            images = images.to(device)

            # Zero gradients
            yolo_model.zero_grad()

            # Forward pass with mixed precision
            # Specify device_type in autocast
            with torch.amp.autocast(device_type='cuda'): # or 'cpu' if using CPU
                outputs = yolo_model(images)
                loss = nn.CrossEntropyLoss()(outputs, labels)  # Ensure labels are available

            # Backward pass and optimization
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (preds == labels).sum().item()

            # Update progress bar with current loss and accuracy
            progress_bar.set_postfix(loss=loss.item(), accuracy=100 * correct / total)

        print(f"End of Epoch [{epoch + 1}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%")

    # Save model checkpoint
    torch.save(yolo_model.state_dict(), os.path.join(model_save_path, f"{backbone_name}_OCT.pth"))
    print(f"Model saved for backbone: {backbone_name}\n")

import os
import glob
import torch
import torch.nn as nn
from torchvision import models, transforms
from yolov5.models.yolo import Model
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import psutil
from PIL import Image
from sklearn.preprocessing import LabelEncoder

# Set paths and configurations
data_path = r"/content/drive/MyDrive/THISIS_PROJECT_OCT/data"
model_save_path = "./models1"
os.makedirs(model_save_path, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
cpu_count = psutil.cpu_count(logical=True)

# Custom Dataset Class
class CustomDataset(Dataset):
    def __init__(self, data_path, mode='train', img_size=(224, 224)):
        self.image_paths = glob.glob(os.path.join(data_path, mode, '*', '*.jpeg'))
        if not self.image_paths:
            raise ValueError(f"No image files found in {os.path.join(data_path, mode)}")
        self.img_size = img_size

        # Extract labels from image paths
        self.labels = [os.path.basename(os.path.dirname(path)) for path in self.image_paths]
        self.label_encoder = LabelEncoder()
        self.labels = self.label_encoder.fit_transform(self.labels)

        # Create a mapping from class index to bounding boxes
        self.bboxes = self.create_bounding_boxes()  # Placeholder for bounding box creation

    def create_bounding_boxes(self):
        # Implement logic to create bounding boxes for each image
        # Format: [x_center, y_center, width, height, class_id]
        # Here we provide dummy bounding boxes; you need to replace this logic with actual bounding box data
        return [[0.5, 0.5, 1.0, 1.0, self.labels[i]] for i in range(len(self.image_paths))]  # Dummy example

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')

        # Resize the image
        transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.ToTensor(),
        ])
        image = transform(image)

        # Create target tensor
        target = self.bboxes[idx]  # Get the bounding box for the current image
        target_tensor = torch.tensor(target, dtype=torch.float32)  # Convert to tensor

        return image, target_tensor

# Backbones to evaluate
backbones = {
    "ResNet50V2": models.resnet50(pretrained=True),
    "EfficientNetB7": models.efficientnet_b7(pretrained=True),
    "InceptionV3": models.inception_v3(pretrained=True),
    "DenseNet201": models.densenet201(pretrained=True),
}

# Custom YOLO loss function
def custom_yolo_loss(predictions, targets):
    """
    Custom YOLO loss function.

    Parameters:
    - predictions: model predictions (logits) from the YOLO model
    - targets: ground truth labels (bounding boxes + class labels)

    Returns:
    - total_loss: computed loss
    """
    # Assuming predictions are of shape [batch_size, num_anchors, grid_size, grid_size, 4+num_classes]
    batch_size = predictions.size(0)

    # Extract predictions
    pred_boxes = predictions[..., :4]  # Bounding box coordinates
    pred_conf = predictions[..., 4:5]  # Objectness score
    pred_cls = predictions[..., 5:]      # Class scores

    # Unpack targets
    target_boxes = targets[..., :4]  # Target bounding boxes
    target_conf = targets[..., 4:5]   # Target objectness score
    target_cls = targets[..., 5:]      # Target class scores

    # Compute loss components
    box_loss = nn.MSELoss()(pred_boxes, target_boxes)  # Adjust based on your box format
    conf_loss = nn.BCEWithLogitsLoss()(pred_conf, target_conf)  # Objectness score loss
    class_loss = nn.BCEWithLogitsLoss()(pred_cls, target_cls)  # Class score loss

    # Total loss
    total_loss = box_loss + conf_loss + class_loss

    return total_loss

# Training function with mixed-precision and CPU-GPU load balancing
def train_with_backbone(backbone_name, backbone_model):
    print(f"\nStarting training with backbone: {backbone_name}")

    # Initialize YOLO model with custom backbone
    yolo_model = Model(cfg=r"/content/yolov5/models/yolov5s.yaml", ch=3, nc=4)
    yolo_model.backbone = backbone_model  # Set the custom backbone

    # Move model to device (GPU) and to half precision
    yolo_model.to(device).half()

    # Create dataset and dataloader
    dataset = CustomDataset(data_path, mode='train')
    train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=cpu_count)

    # Set the optimizer after moving the model
    optimizer = torch.optim.Adam(yolo_model.parameters(), lr=0.001)

    # Mixed precision training setup
    scaler = torch.amp.GradScaler()

    # Define training configuration
    train_cfg = {
        "epochs": 10,
        "weights": yolo_model,
        "name": f"{backbone_name}_OCT",
        "device": device,
        "dataloader": train_loader,
    }

    # Training loop
    for epoch in range(train_cfg["epochs"]):
        running_loss = 0.0

        print(f"\nEpoch {epoch + 1}/{train_cfg['epochs']}")
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{train_cfg['epochs']}", leave=False)

        for images, labels in progress_bar:
            images = images.to(device).half()  # Move images to device and half precision
            labels = labels.to(device)  # Move labels to the same device as images

            # Zero gradients
            yolo_model.zero_grad()

            # Forward pass with mixed precision
            with torch.amp.autocast(device_type='cuda'):
                outputs = yolo_model(images)

            # YOLO output processing
            if isinstance(outputs, list):
                predictions = outputs[0]  # Assuming outputs[0] contains the necessary predictions
            else:
                predictions = outputs.logits  # Use logits from outputs if available

            # Compute loss
            loss = custom_yolo_loss(predictions, labels.unsqueeze(1))  # Adjust to include target shape if necessary

            # Backward pass and optimization
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()

            # Update progress bar with current loss
            progress_bar.set_postfix(loss=loss.item())

        print(f"End of Epoch [{epoch + 1}], Loss: {running_loss / len(train_loader):.4f}")

    # Save model checkpoint
    torch.save(yolo_model.state_dict(), os.path.join(model_save_path, f"{backbone_name}_OCT.pth"))
    print(f"Model saved for backbone: {backbone_name}\n")

# Evaluate model accuracy and mAP
def evaluate_model(weights_path):
    print(f"\nEvaluating model at {weights_path}")
    # Adjust the evaluation logic as per your requirement
    # Note: You will need to implement or adapt the evaluation logic to compute mAP based on your setup.
    # This is a placeholder.
    results = {"mAP": 0.0, "precision": 0.0}  # Replace this with actual evaluation logic
    print(f"Evaluation Results - mAP: {results['mAP']:.4f}, Accuracy: {results['precision']:.4f}")

# Run training and evaluation for each backbone
if __name__ == "__main__":
    for backbone_name, backbone_model in backbones.items():
        # Train with custom backbone
        train_with_backbone(backbone_name, backbone_model)

        # Evaluate model performance
        model_path = os.path.join(model_save_path, f"{backbone_name}_OCT.pth")
        evaluate_model(model_path)

    print("Training and evaluation completed for all backbones.")

import os
import time
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from prettytable import PrettyTable

# Set environment variable to help manage CUDA memory
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

def load_data(data_dir, img_size=(224, 224), batch_size=16):
    transform = transforms.Compose([
        transforms.Resize(img_size),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    train_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'train'), transform=transform)
    test_dataset = datasets.ImageFolder(root=os.path.join(data_dir, 'test'), transform=transform)

    table = PrettyTable(["Dataset", "Total Images", "Classes"])
    table.add_row(["Train", len(train_dataset), len(train_dataset.classes)])
    table.add_row(["Test", len(test_dataset), len(test_dataset.classes)])
    print(table)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)

    return train_loader, test_loader
def select_model(model_name, num_classes):
    if model_name == "InceptionV3":
        model = models.inception_v3(weights=models.Inception_V3_Weights.DEFAULT, aux_logits=True)
        model.fc = nn.Linear(model.fc.in_features, num_classes)

    else:
        raise ValueError("Model not supported.")
    return model

def train_and_evaluate(data_dir, model_name, num_classes=4, epochs=10, batch_size=980, device="cuda"):
    device = torch.device(device if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device} for {model_name}")

    # Set image size depending on model
    img_size = (299, 299) if model_name == "InceptionV3" else (224, 224)
    train_loader, test_loader = load_data(data_dir, img_size=img_size, batch_size=batch_size)

    model = select_model(model_name, num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)
    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None

    model.train()
    for epoch in range(epochs):
        running_loss, correct, total = 0.0, 0, 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{epochs} - {model_name}", leave=False)
        start_time = time.time()

        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()

            with torch.amp.autocast(device_type=device.type):
                outputs = model(images)
                # Access the logits tensor from InceptionOutputs
                loss = criterion(outputs.logits, labels)

            if scaler:
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.logits.data, 1) # Use logits for prediction
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            progress_bar.set_postfix(loss=loss.item(), accuracy=correct / total)
        epoch_loss = running_loss / len(train_loader)
        epoch_accuracy = correct / total
        elapsed_time = time.time() - start_time
        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Time: {elapsed_time:.2f}s")

    # Save model weights
    torch.save(model.state_dict(), f"model/{model_name}_best_model.pth")
    print(f"Model saved as {model_name}_best_model.pth")

    # Evaluation
    model.eval()
    all_preds, all_labels, total_loss, correct, total = [], [], 0.0, 0, 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    avg_loss = total_loss / len(test_loader)
    accuracy = correct / total
    cm = confusion_matrix(all_labels, all_preds)
    print(f"{model_name} - Average Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}")
    print("Confusion Matrix:\n", cm)
    print("Classification Report:\n", classification_report(all_labels, all_preds))

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=["CNV", "DME", "DRUSEN", "NORMAL"], yticklabels=["CNV", "DME", "DRUSEN", "NORMAL"])
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(f'{model_name} Confusion Matrix')
    plt.show()

# Running different models
if __name__ == "__main__":
    data_dir = r"/content/drive/MyDrive/THISIS_PROJECT_OCT/data"
    results = {}
    for model_name in [ "InceptionV3"]:
        print(f"\nTraining and Evaluating {model_name}...\n")
        accuracy = train_and_evaluate(data_dir, model_name)
        results[model_name] = accuracy

import os
import time
import torch
import torch.nn as nn
from torchvision import models, datasets, transforms
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
from prettytable import PrettyTable

# Set environment variable to help manage CUDA memory
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

def load_data(data_dir, img_size=(224, 224), batch_size=16):
    # ... (Your load_data function remains the same) ...

def select_model(model_name, num_classes):
    # ... (Your select_model function remains the same) ...

def train_and_evaluate(data_dir, model_name, num_classes=4, epochs=10, batch_size=16, device="cuda"):
    device = torch.device(device if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device} for {model_name}")

    # Set image size depending on model
    img_size = (299, 299) if model_name == "InceptionV3" else (224, 224)
    train_loader, test_loader = load_data(data_dir, img_size=img_size, batch_size=batch_size)

    model = select_model(model_name, num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)
    scaler = torch.amp.GradScaler() if device.type == 'cuda' else None

    model.train()
    for epoch in range(epochs):
        running_loss, correct, total = 0.0, 0, 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{epochs} - {model_name}", leave=False)
        start_time = time.time()

        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()

            with torch.amp.autocast(device_type=device.type):
                outputs = model(images)
                # Access the logits tensor from InceptionOutputs
                loss = criterion(outputs.logits, labels)

            if scaler:
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                loss.backward()
                optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs.logits.data, 1) # Use logits for prediction
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            progress_bar.set_postfix(loss=loss.item(), accuracy=correct / total)

        # ... (Rest of the training loop remains the same) ...

    # Evaluation
    model.eval()
    all_preds, all_labels, total_loss, correct, total = [], [], 0.0, 0, 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            # Access the logits tensor from InceptionOutputs
            loss = criterion(outputs.logits, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs.logits, 1) # Use logits for prediction
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    # ... (Rest of the evaluation code remains the same) ...

# ... (Your main execution block remains the same) ...